{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "854b43a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML 응답은 성공했으나 표(tr) 데이터를 찾지 못했습니다.\n",
      "응답 본문 앞부분 일부: <script>\n",
      "var kyC = \"\";\n",
      "var bju = [\"elKPw==Myr\", \"QTSaw==zan\", \"vjHdw==Hwh\", \"sEecA==eTY\", \"bVEbw==GnT\", \"ptTQQ==hqR\", \"HqSDQ==UiH\", \"HjhPw==Azq\", \"hHGaw==dVJ\", \"bWQaA==DfJ\", \"tGLZA==pYK\", \"IUkZw==JxJ\", \"ANjQQ==fSx\", \"jRIDQ==Bqv\", \"dzFPw==QjP\", \"PrJcA==tow\", \"EalaA==vmg\", \"DOYdw==Rhc\", \"NVOZA==hCI\", \"EUlIw==CIM\", \"EEhaw==Gmx\", \"JxOdw==jWE\", \"ZQSdw==UPc\", \"WVQcw==wTV\", \"JbwMA==cou\", \"ZMpaA==fjs\", \"MkidA==Auk\", \"zPKeA==TNj\", \"yknbA==ORH\", \"ksOeQ==Abx\", \"KjMQA==QPr\", \"fdDJQ==smY\", \"hnhRg==DNi\", \"Zlz\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = \"https://www.fmkorea.com/search.php?mid=stock&listStyle=list&search_keyword=%EC%82%BC%EC%84%B1&search_target=title_content&page=1\"\n",
    "\n",
    "all_data = []\n",
    "\n",
    "try:\n",
    "    res = requests.get(url)\n",
    "    soup = bs(res.text, \"lxml\")\n",
    "    rows = soup.find_all(\"tr\")\n",
    "\n",
    "    for r in rows:\n",
    "        cols = r.find_all(\"td\")\n",
    "        if not cols:\n",
    "            continue\n",
    "        row_data = [c.get_text(strip=True) for c in cols]\n",
    "        all_data.append(row_data)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")\n",
    "\n",
    "# 3. 데이터프레임으로 변환 (컬럼 개수가 다를 수 있으므로 기본 출력)\n",
    "if all_data:\n",
    "    # 최대 컬럼 수에 맞춰 데이터프레임 생성\n",
    "    df = pd.DataFrame(all_data)\n",
    "    print(f\"--- 전체 수집 결과 (총 {len(df)}행) ---\")\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"HTML 응답은 성공했으나 표(tr) 데이터를 찾지 못했습니다.\")\n",
    "    print(\"응답 본문 앞부분 일부:\", res.text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f7742",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4a01865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] page=1 total_rows=20\n",
      "[OK] page=2 total_rows=40\n",
      "[OK] page=3 total_rows=60\n",
      "[OK] page=4 total_rows=80\n",
      "[OK] page=5 total_rows=100\n",
      "[OK] page=6 total_rows=120\n",
      "[OK] page=7 total_rows=140\n",
      "[OK] page=8 total_rows=160\n",
      "[OK] page=9 total_rows=180\n",
      "[OK] page=10 total_rows=200\n",
      "saved: 200\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "\n",
    "BASE_URL = \"https://www.fmkorea.com/search.php\"\n",
    "BASE_PARAMS = {\n",
    "    \"mid\": \"stock\",\n",
    "    \"category\": \"2997203870\",\n",
    "    \"search_keyword\": \"삼성전자\",\n",
    "    \"search_target\": \"title_content\",\n",
    "    \"listStyle\": \"list\",\n",
    "}\n",
    "\n",
    "SLEEP_SEC = 2\n",
    "MAX_RETRY = 3\n",
    "\n",
    "def parse_one_page(html: str):\n",
    "    soup = bs(html, \"html.parser\")\n",
    "    table = soup.select_one(\"table.bd_lst.bd_tb_lst.bd_tb\")\n",
    "    tbody = table.select_one(\"tbody\") if table else None\n",
    "    rows = tbody.select(\"tr\") if tbody else []\n",
    "\n",
    "    out = []\n",
    "    for tr in rows:\n",
    "        td_cate = tr.select_one(\"td.cate a\")\n",
    "        td_title_a = tr.select_one(\"td.title a.hx\")\n",
    "        td_author = tr.select_one(\"td.author a\")\n",
    "        td_time = tr.select_one(\"td.time\")\n",
    "        tds_mno = tr.select(\"td.m_no\")\n",
    "\n",
    "        if not (td_cate and td_title_a and td_author and td_time and len(tds_mno) >= 2):\n",
    "            continue\n",
    "\n",
    "        views = tds_mno[0].get_text(strip=True)\n",
    "        votes = tds_mno[1].get_text(strip=True)\n",
    "\n",
    "        out.append({\n",
    "            \"탭\": td_cate.get_text(strip=True),\n",
    "            \"제목\": td_title_a.get_text(\" \", strip=True),\n",
    "            \"글쓴이\": td_author.get_text(strip=True),\n",
    "            \"날짜\": td_time.get_text(strip=True),\n",
    "            \"조회\": int(views.replace(\",\", \"\")) if views else None,\n",
    "            \"추천\": int(votes.replace(\",\", \"\")) if votes else None,\n",
    "        })\n",
    "    return out\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "with requests.Session() as s:\n",
    "    for page in range(1, 11):  # 테스트용\n",
    "        params = dict(BASE_PARAMS)\n",
    "        params[\"page\"] = page\n",
    "\n",
    "        ok = False\n",
    "        for attempt in range(1, MAX_RETRY + 1):\n",
    "            try:\n",
    "                r = s.get(BASE_URL, params=params, timeout=200)\n",
    "                r.raise_for_status()  # 4xx/5xx면 예외 발생 [web:142]\n",
    "\n",
    "                all_rows.extend(parse_one_page(r.text))\n",
    "                ok = True\n",
    "                break\n",
    "\n",
    "            except requests.RequestException as e:\n",
    "                # 실패하면 더 길게 쉬었다가 재시도(점점 증가) = backoff [web:133]\n",
    "                wait = 60 * attempt   # 60초, 120초, 180초...\n",
    "                print(f\"[FAIL] page={page} attempt={attempt}/{MAX_RETRY} err={e}\")\n",
    "                print(f\"-> {wait}초 쉬고 재시도\")\n",
    "                time.sleep(wait)\n",
    "\n",
    "        if ok:\n",
    "            print(f\"[OK] page={page} total_rows={len(all_rows)}\")\n",
    "        else:\n",
    "            print(f\"[SKIP] page={page} (재시도 {MAX_RETRY}회 실패)\")\n",
    "\n",
    "        time.sleep(SLEEP_SEC)\n",
    "\n",
    "df = pd.DataFrame(all_rows)\n",
    "df.to_csv(\"fmkorea_search_page1_500.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"saved:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bdc0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "\n",
    "url_base = \"https://www.fmkorea.com/search.php?mid=stock&category=2997203870&search_keyword=%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90&search_target=title_content&listStyle=list&page={}\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"탭\": [],\n",
    "    \"제목\": [],\n",
    "    \"글쓴이\": [],\n",
    "    \"날짜\": [],\n",
    "    \"조회\": [],\n",
    "    \"추천\": [],\n",
    "}\n",
    "\n",
    "for page in range(1, 501):\n",
    "    url = url_base.format(page)\n",
    "    r = requests.get(url, headers=headers, timeout=2000)\n",
    "    r.raise_for_status()  # 요청 실패면 에러 내고 멈춤 [web:53]\n",
    "\n",
    "    soup = bs(r.text, \"lxml\")\n",
    "\n",
    "    # 글 목록 행(tr)들\n",
    "    rows = soup.select(\"table.bd_lst.bd_tb_lst.bd_tb tbody tr\")  # select 사용 [web:39]\n",
    "\n",
    "    for tr in rows:\n",
    "        cate_a = tr.select_one(\"td.cate a\")\n",
    "        title_a = tr.select_one(\"td.title a.hx\")\n",
    "        author_a = tr.select_one(\"td.author a\")\n",
    "        time_td = tr.select_one(\"td.time\")\n",
    "        mno_tds = tr.select(\"td.m_no\")\n",
    "\n",
    "        # 공지/광고처럼 구조가 다르면 스킵\n",
    "        if not (cate_a and title_a and author_a and time_td and len(mno_tds) >= 2):\n",
    "            continue\n",
    "\n",
    "        views = mno_tds[0].get_text(strip=True)\n",
    "        votes = mno_tds[1].get_text(strip=True)\n",
    "\n",
    "        data[\"탭\"].append(cate_a.get_text(strip=True))\n",
    "        data[\"제목\"].append(title_a.get_text(\" \", strip=True))\n",
    "        data[\"글쓴이\"].append(author_a.get_text(strip=True))\n",
    "        data[\"날짜\"].append(time_td.get_text(strip=True))\n",
    "        data[\"조회\"].append(int(views.replace(\",\", \"\")) if views else None)\n",
    "        data[\"추천\"].append(int(votes.replace(\",\", \"\")) if votes else None)\n",
    "\n",
    "    print(f\"{page}페이지 완료 / 누적 {len(data['제목'])}개\")\n",
    "    time.sleep(1.5)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv(\"fmkorea_page_1_500.csv\", index=False, encoding=\"utf-8\")\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
