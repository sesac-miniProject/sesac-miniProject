{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae1b8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 자동 인식된 파일\n",
      " - 현대차: fm_hyundai_normal.csv\n",
      "\n",
      "⚠️ 못 찾은 대상: 삼성, 하이닉스\n",
      "   파일명이 너무 다르면 TARGETS 키워드를 추가하거나 파일명을 바꿔주세요.\n",
      "\n",
      "[저장] 현대차 일별집계(OI포함) CSV -> C:\\Users\\Jeon\\sesac-miniProject\\완료\\daily_outputs\\현대차_일별집계_OI포함_2025-01-14_2026-01-14.csv\n",
      "[저장] 요약 CSV -> C:\\Users\\Jeon\\sesac-miniProject\\완료\\daily_outputs\\2종목_요약_OI포함_2025-01-14_2026-01-14.csv\n",
      "\n",
      "==== 화면 요약(핵심만) ====\n",
      "    종목   총게시글  최다게시글수(하루)   최다게시글_날짜들        일평균조회수     일조회수_표준편차  \\\n",
      "0  현대차  10793         402  2026-01-07  29985.505464  55191.225279   \n",
      "\n",
      "   과열지수_OI_최댓값 과열지수_OI_최대날짜들    과열지수_OI_평균  과열지수_OI_표준편차  \n",
      "0     6.755664    2025-10-30  3.882747e-17      0.989209  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 0) 설정 (여기만 수정)\n",
    "# =========================\n",
    "DATA_DIR = r\"C:\\Users\\Jeon\\sesac-miniProject\\완료\"\n",
    "START_DATE = pd.to_datetime(\"2025-01-14\").date()\n",
    "END_DATE   = pd.to_datetime(\"2026-01-14\").date()\n",
    "\n",
    "OUT_DIR = os.path.join(DATA_DIR, \"daily_outputs\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# 파일명에 포함된 키워드로 자동 매칭 (현대차 제외)\n",
    "TARGETS = {\n",
    "    \"삼성\": [\"삼성\", \"samsung\"],\n",
    "    \"하이닉스\": [\"하이닉스\", \"sk하이닉스\", \"hynix\"],\n",
    "    \"현대차\": [\"현대차\", \"현대 자동차\", \"hyundai\"]\n",
    "}\n",
    "\n",
    "# ✅ 과열지수(OI) 가중치\n",
    "W_VIEWS    = 0.25\n",
    "W_POSTS    = 0.25\n",
    "W_COMMENTS = 0.30\n",
    "W_LIKES    = 0.20\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) 유틸\n",
    "# =========================\n",
    "def to_int_series(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(str).str.replace(\",\", \"\", regex=False)\n",
    "    s = s.str.extract(r\"(\\d+)\")[0].fillna(\"0\")\n",
    "    return s.astype(int)\n",
    "\n",
    "\n",
    "def find_file_for_target(csv_files, keywords):\n",
    "    lower_map = [(f, os.path.basename(f).lower()) for f in csv_files]\n",
    "    for kw in keywords:\n",
    "        kw_l = kw.lower()\n",
    "        for f, base in lower_map:\n",
    "            if kw_l in base:\n",
    "                return f\n",
    "    return None\n",
    "\n",
    "\n",
    "def daily_aggregate(csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path, encoding=\"utf-8-sig\")\n",
    "\n",
    "    # ✅ 네 CSV 컬럼명(한글) -> 내부 표준 컬럼명(영문)으로 매핑\n",
    "    rename_map = {\n",
    "        \"날짜\": \"date\",\n",
    "        \"제목\": \"title\",\n",
    "        \"조회\": \"views\",\n",
    "        \"추천\": \"likes\",\n",
    "        \"댓글수\": \"comments\",\n",
    "    }\n",
    "    df = df.rename(columns=rename_map)\n",
    "\n",
    "    # ✅ 날짜 포맷이 이미 'YYYY-MM-DD'로 고정이라면, 추가 전처리 없이 바로 파싱\n",
    "    dt = pd.to_datetime(df[\"date\"], errors=\"coerce\")  # 문자열 -> datetime [web:231]\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"date_dt\"] = dt.dt.date\n",
    "    df = df.dropna(subset=[\"date_dt\"])\n",
    "    df = df[(df[\"date_dt\"] >= START_DATE) & (df[\"date_dt\"] <= END_DATE)]\n",
    "\n",
    "    if \"title\" not in df.columns:\n",
    "        df[\"title\"] = \"\"\n",
    "    for col in [\"views\", \"likes\", \"comments\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "\n",
    "    df[\"views\"] = to_int_series(df[\"views\"])\n",
    "    df[\"likes\"] = to_int_series(df[\"likes\"])\n",
    "    df[\"comments\"] = to_int_series(df[\"comments\"])\n",
    "\n",
    "    daily = (\n",
    "        df.groupby(\"date_dt\", as_index=False)\n",
    "          .agg(\n",
    "              posts=(\"title\", \"size\"),\n",
    "              views=(\"views\", \"sum\"),\n",
    "              comments=(\"comments\", \"sum\"),\n",
    "              likes=(\"likes\", \"sum\"),\n",
    "          )\n",
    "    )\n",
    "\n",
    "    # ✅ 기간 전체 날짜를 채움(글 없는 날 0)\n",
    "    full = pd.DataFrame({\"date_dt\": pd.date_range(START_DATE, END_DATE, freq=\"D\").date})\n",
    "    daily = full.merge(daily, on=\"date_dt\", how=\"left\").fillna(0)\n",
    "\n",
    "    for c in [\"posts\", \"views\", \"comments\", \"likes\"]:\n",
    "        daily[c] = daily[c].astype(int)\n",
    "\n",
    "    daily = daily.sort_values(\"date_dt\")\n",
    "    daily[\"date\"] = pd.to_datetime(daily[\"date_dt\"]).dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    daily = daily[[\"date\", \"posts\", \"views\", \"comments\", \"likes\"]].rename(columns={\n",
    "        \"date\": \"날짜\",\n",
    "        \"posts\": \"게시글수\",\n",
    "        \"views\": \"조회수\",\n",
    "        \"comments\": \"댓글수\",\n",
    "        \"likes\": \"좋아요수\",\n",
    "    })\n",
    "    return daily\n",
    "\n",
    "\n",
    "def summarize_basic(daily: pd.DataFrame):\n",
    "    max_posts = int(daily[\"게시글수\"].max())\n",
    "    top_days = daily[daily[\"게시글수\"] == max_posts][[\"날짜\", \"게시글수\", \"조회수\", \"댓글수\", \"좋아요수\"]]\n",
    "\n",
    "    avg_daily_views = float(daily[\"조회수\"].mean())\n",
    "    std_daily_views = float(daily[\"조회수\"].std(ddof=1))\n",
    "\n",
    "    return {\n",
    "        \"기간일수\": int(len(daily)),\n",
    "        \"글있는날\": int((daily[\"게시글수\"] > 0).sum()),\n",
    "        \"총게시글\": int(daily[\"게시글수\"].sum()),\n",
    "        \"일평균조회수\": avg_daily_views,\n",
    "        \"일조회수_표준편차\": std_daily_views,\n",
    "        \"최다게시글수(하루)\": max_posts,\n",
    "        \"최다게시글_날짜들\": \", \".join(top_days[\"날짜\"].tolist()),\n",
    "    }, top_days\n",
    "\n",
    "\n",
    "def zscore(series: pd.Series) -> pd.Series:\n",
    "    mu = series.mean()\n",
    "    sd = series.std(ddof=1)\n",
    "    if sd == 0 or np.isnan(sd):\n",
    "        return pd.Series(np.zeros(len(series)), index=series.index)\n",
    "    return (series - mu) / sd\n",
    "\n",
    "\n",
    "def add_overheat_index(daily: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = daily.copy()\n",
    "\n",
    "    d[\"조회수_z\"] = zscore(d[\"조회수\"])\n",
    "    d[\"게시글수_z\"] = zscore(d[\"게시글수\"])\n",
    "    d[\"댓글수_z\"] = zscore(d[\"댓글수\"])\n",
    "    d[\"좋아요수_z\"] = zscore(d[\"좋아요수\"])\n",
    "\n",
    "    d[\"과열지수_OI\"] = (\n",
    "        W_VIEWS    * d[\"조회수_z\"] +\n",
    "        W_POSTS    * d[\"게시글수_z\"] +\n",
    "        W_COMMENTS * d[\"댓글수_z\"] +\n",
    "        W_LIKES    * d[\"좋아요수_z\"]\n",
    "    )\n",
    "    return d\n",
    "\n",
    "\n",
    "def summarize_oi(daily_with_oi: pd.DataFrame):\n",
    "    max_oi = daily_with_oi[\"과열지수_OI\"].max()\n",
    "    top_oi_days = daily_with_oi[daily_with_oi[\"과열지수_OI\"] == max_oi][\n",
    "        [\"날짜\", \"과열지수_OI\", \"게시글수\", \"조회수\", \"댓글수\", \"좋아요수\"]\n",
    "    ].copy()\n",
    "\n",
    "    return {\n",
    "        \"과열지수_OI_평균\": float(daily_with_oi[\"과열지수_OI\"].mean()),\n",
    "        \"과열지수_OI_표준편차\": float(daily_with_oi[\"과열지수_OI\"].std(ddof=1)),\n",
    "        \"과열지수_OI_최댓값\": float(max_oi),\n",
    "        \"과열지수_OI_최대날짜들\": \", \".join(top_oi_days[\"날짜\"].tolist()),\n",
    "    }, top_oi_days\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) 실행: 파일 자동 찾기\n",
    "# =========================\n",
    "csv_files = glob.glob(os.path.join(DATA_DIR, \"*.csv\"))\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"'{DATA_DIR}' 폴더에 CSV가 없습니다. DATA_DIR을 확인하세요.\")\n",
    "\n",
    "picked = {}\n",
    "missing = []\n",
    "for name, kws in TARGETS.items():\n",
    "    f = find_file_for_target(csv_files, kws)\n",
    "    if f:\n",
    "        picked[name] = f\n",
    "    else:\n",
    "        missing.append(name)\n",
    "\n",
    "print(\"✅ 자동 인식된 파일\")\n",
    "for k, v in picked.items():\n",
    "    print(f\" - {k}: {os.path.basename(v)}\")\n",
    "\n",
    "if missing:\n",
    "    print(\"\\n⚠️ 못 찾은 대상:\", \", \".join(missing))\n",
    "    print(\"   파일명이 너무 다르면 TARGETS 키워드를 추가하거나 파일명을 바꿔주세요.\\n\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) 종목별: 일별 집계 + OI 계산 + 저장 (CSV만)\n",
    "# =========================\n",
    "daily_tables = {}\n",
    "summary_rows = []\n",
    "top_posts_all = []\n",
    "top_oi_all = []\n",
    "\n",
    "for stock, path in picked.items():\n",
    "    daily = daily_aggregate(path)\n",
    "    daily_oi = add_overheat_index(daily)\n",
    "    daily_tables[stock] = daily_oi\n",
    "\n",
    "    # 종목별 CSV 저장 (OI 포함)\n",
    "    out_csv = os.path.join(OUT_DIR, f\"{stock}_일별집계_OI포함_{START_DATE}_{END_DATE}.csv\")\n",
    "    daily_oi.to_csv(out_csv, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[저장] {stock} 일별집계(OI포함) CSV -> {out_csv}\")\n",
    "\n",
    "    # 요약용 데이터 만들기\n",
    "    basic_summ, top_days = summarize_basic(daily)\n",
    "    oi_summ, top_oi_days = summarize_oi(daily_oi)\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"종목\": stock,\n",
    "        \"원본파일\": os.path.basename(path),\n",
    "        **basic_summ,\n",
    "        **oi_summ\n",
    "    })\n",
    "\n",
    "    tmp1 = top_days.copy()\n",
    "    tmp1.insert(0, \"종목\", stock)\n",
    "    top_posts_all.append(tmp1)\n",
    "\n",
    "    tmp2 = top_oi_days.copy()\n",
    "    tmp2.insert(0, \"종목\", stock)\n",
    "    top_oi_all.append(tmp2)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "# 요약 CSV 저장 (파일명은 그대로 두되, 실제 내용은 2종목만 들어감)\n",
    "summary_csv = os.path.join(OUT_DIR, f\"2종목_요약_OI포함_{START_DATE}_{END_DATE}.csv\")\n",
    "summary_df.to_csv(summary_csv, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"[저장] 요약 CSV -> {summary_csv}\")\n",
    "\n",
    "# (선택) 최다 게시글 날짜들/최대 OI 날짜들도 CSV로 저장\n",
    "# if top_posts_all:\n",
    "#     top_posts_csv = os.path.join(OUT_DIR, f\"최다게시글날짜_{START_DATE}_{END_DATE}.csv\")\n",
    "#     pd.concat(top_posts_all, ignore_index=True).to_csv(top_posts_csv, index=False, encoding=\"utf-8-sig\")\n",
    "#     print(f\"[저장] 최다 게시글 날짜 CSV -> {top_posts_csv}\")\n",
    "\n",
    "# if top_oi_all:\n",
    "#     top_oi_csv = os.path.join(OUT_DIR, f\"최대OI날짜_{START_DATE}_{END_DATE}.csv\")\n",
    "#     pd.concat(top_oi_all, ignore_index=True).to_csv(top_oi_csv, index=False, encoding=\"utf-8-sig\")\n",
    "#     print(f\"[저장] 최대 OI 날짜 CSV -> {top_oi_csv}\")\n",
    "\n",
    "\n",
    "print(\"\\n==== 화면 요약(핵심만) ====\")\n",
    "print(summary_df[\n",
    "    [\"종목\",\n",
    "     \"총게시글\",\n",
    "     \"최다게시글수(하루)\",\n",
    "     \"최다게시글_날짜들\",\n",
    "     \"일평균조회수\",\n",
    "     \"일조회수_표준편차\",\n",
    "     \"과열지수_OI_최댓값\",\n",
    "     \"과열지수_OI_최대날짜들\",\n",
    "     \"과열지수_OI_평균\",\n",
    "     \"과열지수_OI_표준편차\"\n",
    "     ]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ee628b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on\n"
     ]
    }
   ],
   "source": [
    "print(\"on\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sesac-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
